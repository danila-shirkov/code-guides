---
title: Cómo y por qué utilizar Docker
subtitle: Un programa que permite a un sistema operativo ejecutar procesos en un entorno aislado basado en imágenes especialmente creadas.
description: ¿Cómo se crea la infraestructura de proyectos, se compilan y ejecutan servicios? Hablamos sobre el aislamiento de procesos en un sistema operativo sin virtualización pesada.
image: "/assets/images/docker/docker.png"
author: Kirill Mokevnin
---

**Docker es un programa que permite a un sistema operativo ejecutar procesos en un entorno aislado basado en imágenes especialmente creadas. A pesar de que las tecnologías en las que se basa Docker existían antes que él, Docker revolucionó la forma en que se crea la infraestructura de proyectos, se compilan y ejecutan servicios en la actualidad.**

*(En este artículo se omiten muchos detalles a propósito para no sobrecargar con información que no es necesaria para la comprensión).*

## Instalación

Para comenzar a utilizar Docker, es necesario instalar el motor: Docker Engine. En la página https://docs.docker.com/engine/install/ se encuentran disponibles enlaces de descarga para todas las plataformas populares. Elija la suya e instale Docker.

<Banner name="intensive-devops" />

Al trabajar con Docker, hay un detalle importante que debe conocer al instalarlo en Mac y Linux. Por defecto, Docker funciona a través de un socket Unix. Por motivos de seguridad, el socket está cerrado para los usuarios que no pertenecen al grupo _docker_. Aunque el instalador agrega automáticamente al usuario actual a este grupo, Docker no funcionará de inmediato. Esto se debe a que si el usuario cambia el grupo por sí mismo, nada cambiará hasta que el usuario vuelva a iniciar sesión. Esta es una característica del kernel. Para verificar a qué grupos pertenece su usuario, puede ejecutar el comando `id`.

Puede verificar el éxito de la instalación con el comando `docker info`:

```shell
$ docker info
Containers: 22
 Running: 2
 Paused: 0
 Stopped: 20
Images: 72
Server Version: 17.12.0-ce
Storage Driver: overlay2
 Backing Filesystem: extfs
 Supports d_type: true
 Native Overlay Diff: true
Logging Driver: json-file
Cgroup Driver: cgroupfs
...
```

Proporciona mucha información sobre la configuración de Docker y las estadísticas de funcionamiento.

## Ejecución

En esta etapa, los comandos se ejecutan "tal cual" sin explicar los detalles. Más adelante se explicará cómo se forman y qué incluyen.

Comencemos con la opción más simple:

```shell
$ docker run -it nginx bash
root@a6c26812d23b:/#
```

En la primera ejecución, este comando comenzará a descargar la imagen _nginx_, por lo que tendrá que esperar un poco. Después de que se descargue la imagen, se ejecutará _bash_ y se encontrará **dentro del contenedor** (container).

Explore el sistema de archivos, vea el directorio */etc/nginx*. Como puede ver, su contenido no coincide con el que tiene en su computadora. Este sistema de archivos proviene de la imagen _nginx_. Cualquier cosa que haga aquí dentro no afectará su sistema de archivos principal. Puede salir del contenedor con el comando `exit`.

Ahora veamos un ejemplo de ejecución del comando `cat` en otro contenedor, pero también iniciado desde la imagen _nginx_:

```shell
$ docker run nginx cat /etc/nginx/nginx.conf

user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;
...
$
```

El comando se ejecuta casi instantáneamente, ya que la imagen ya está descargada. A diferencia del inicio anterior, donde se ejecuta _bash_ y se inicia una sesión interactiva dentro del contenedor, la ejecución del comando `cat /etc/nginx/nginx.conf` para la imagen _nginx_ mostrará el contenido del archivo especificado (tomado del sistema de archivos del contenedor en ejecución) y devolverá el control al lugar donde estaba. No estará dentro del contenedor.

El último método de inicio será el siguiente:

```shell
# Tenga en cuenta que después del nombre de la imagen no se especifica ningún comando.
# Este enfoque funciona si el comando de inicio está especificado en la propia imagen
$ docker run -p 8080:80 nginx
```

Este comando no devuelve el control, ya que inicia nginx. Abra su navegador y escriba `localhost:8080`. Verá cómo se carga la página _Welcome to nginx!_. Si en este momento vuelve a mirar la consola donde se inició el contenedor, verá que se muestra el registro de solicitudes a `localhost:8080`. Puede detener nginx con el comando <kbd>Ctrl + C</kbd>.

A pesar de que todas las ejecuciones se realizaron de manera diferente y dieron diferentes resultados, el proceso general es el mismo. Docker descarga automáticamente la imagen (el primer argumento después de `docker run`) y, en base a ella, inicia un contenedor con el comando especificado.

**Una imagen es un sistema de archivos independiente**. Por ahora, estamos utilizando imágenes predefinidas, pero luego aprenderemos a crear las nuestras propias.

**Un contenedor es un proceso en ejecución del sistema operativo en un entorno aislado** con un sistema de archivos conectado desde la imagen.

Reitero que un contenedor es simplemente un proceso normal de su sistema operativo. La diferencia es que, gracias a las capacidades del kernel (que se explicarán al final), Docker inicia el proceso en un entorno aislado. El contenedor ve su propia lista de procesos, su propia red, su propio sistema de archivos, etc. A menos que se le indique explícitamente, no puede interactuar con su sistema operativo principal y todo lo que contiene o se ejecuta en él.

Intente ejecutar el comando `docker run -it ubuntu bash` y escriba `ps auxf` dentro del contenedor en ejecución. La salida será la siguiente:

```shell
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.1  0.1  18240  3300 pts/0    Ss   15:39   0:00 /bin/bash
root        12  0.0  0.1  34424  2808 pts/0    R+   15:40   0:00 ps aux
```

Como puede ver, solo hay dos procesos y el PID de Bash es 1. También puede ver el directorio */home* con el comando `ls /home` y asegurarse de que está vacío. También tenga en cuenta que el usuario predeterminado dentro del contenedor es `root`.

## ¿Para qué es todo esto?

**Docker es una forma universal de entregar aplicaciones a máquinas (computadoras locales o servidores remotos) y ejecutarlas en un entorno aislado**.

Recuerde cuando tuvo que compilar programas a partir de código fuente. Este proceso incluye los siguientes pasos:

* Instalar todas las dependencias necesarias para su sistema operativo (debe encontrar la lista de ellas).
* Descargar el archivo comprimido y descomprimirlo.
* Ejecutar la configuración `make configure`.
* Ejecutar la compilación `make compile`.
* Instalar `make install`.

Como puede ver, el proceso no es trivial y a menudo no es rápido. A veces incluso es imposible debido a errores inexplicables. Y eso sin mencionar la contaminación del sistema operativo.

Docker simplifica este procedimiento a la ejecución de un solo comando con casi un 100% de garantía de éxito. Eche un vistazo al ejemplo ficticio en el que se instala el programa Tunnel en su computadora local en el directorio */usr/local/bin* utilizando la imagen _tunnel_:

```shell
docker run -v /usr/local/bin:/out tunnel
```

Ejecutar este comando hará que el archivo ejecutable del programa, que se encuentra dentro de la imagen _tunnel_, aparezca en el sistema de archivos principal en el directorio */usr/local/bin*. Ahora puede iniciar el programa simplemente escribiendo `tunnel` en la terminal.

¿Y si el programa que instalamos de esta manera tiene dependencias? El truco está en que la imagen en la que se ejecuta ya tiene todas las dependencias instaladas, y su inicio garantiza casi un 100% de funcionalidad independientemente del estado del sistema operativo principal.

A menudo, ni siquiera es necesario copiar el programa del contenedor a su sistema operativo principal. Es suficiente con ejecutar el propio contenedor cuando sea necesario. Supongamos que decidimos desarrollar un sitio estático basado en Jekyll. Jekyll es un generador de sitios estáticos popular escrito en Ruby. Por ejemplo, el tutorial que está leyendo ahora mismo se encuentra en un sitio estático generado con Jekyll. Y al generarlo, se utilizó Docker (puede leer más sobre esto en el tutorial: [cómo crear un blog con Jekyll](https://guides.hexlet.io/jekyll/)).

El antiguo método de uso de Jekyll requería instalar Ruby y Jekyll como una gema (gem es el nombre de los paquetes en Ruby) en su sistema operativo principal. Y, como siempre en tales casos, Jekyll solo funciona con versiones específicas de Ruby, lo que complica la configuración.

Con Docker, el inicio de Jekyll se reduce a un solo comando que se ejecuta en el directorio del blog (puede encontrar más detalles en el [repositorio](https://github.com/hexletguides/hexletguides.github.io) de nuestros tutoriales):

```shell
docker run --rm --volume="$PWD:/srv/jekyll" -it jekyll/jekyll jekyll server
```

Así es como se inicia Jekyll en la práctica. Cuanto más lejos, más se utiliza este enfoque. En este punto, puede sumergirse un poco en el origen del nombre Docker.

![docker logo](/assets/images/docker/docker_logo.png)

Como saben, el principal medio de transporte de mercancías en todo el mundo son los barcos. Antes, el costo del transporte era bastante alto debido a que cada carga tenía su propia forma y tipo de material.

![loading cargo onto a ship](/assets/images/docker/cargo.jpg)

Cargar un saco de pescado o un automóvil en un barco son tareas diferentes que requieren diferentes procesos e instrumentos. Había problemas con los métodos de carga, se requerían diferentes grúas e instrumentos. Y empaquetar eficientemente la carga en el barco, teniendo en cuenta su fragilidad, era una tarea no trivial.

Pero en algún momento todo cambió. Una imagen vale más que mil palabras:

![shipping container terminal](/assets/images/docker/container_terminal.jpg)

Los contenedores igualaron todos los tipos de carga y estandarizaron los instrumentos de carga y descarga en todo el mundo. Lo que a su vez llevó a la simplificación de los procesos, la aceleración y, por lo tanto, la reducción de los costos de transporte.

Lo mismo sucedió en el desarrollo de software. Docker se convirtió en un medio universal de entrega de software independientemente de su estructura, dependencias y método de instalación. Todo lo que necesitan los programas distribuidos a través de Docker se encuentra dentro de la imagen y no se cruza con el sistema operativo principal y todo lo que contiene o se ejecuta en él.